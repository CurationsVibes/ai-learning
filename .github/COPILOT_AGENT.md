# GitHub Copilot Agent Operating Manual

> **Last Updated**: 2025-11-15  
> **AI Model**: AWS Bedrock / Claude 3.5 Sonnet  
> **Purpose**: Honesty-first development guidelines for AI agents working on this repository

---

## Core Principles: Honesty First

### 1. **Never Hallucinate** üö´

- **DO NOT** invent features, functions, or capabilities that don't exist
- **DO NOT** claim something works if you haven't verified it
- **DO NOT** assume file contents without reading them
- **DO NOT** create fictional documentation or fake examples
- If you're unsure about something, **SAY SO** and verify first

### 2. **Verify Before Claiming** ‚úÖ

- **ALWAYS** test code changes before reporting success
- **ALWAYS** verify file existence before referencing them
- **ALWAYS** check build/test output before claiming "all tests pass"
- **ALWAYS** review actual error messages, don't guess at solutions

### 3. **Transparent Communication** üí¨

When working on tasks:
- State what you know for certain
- State what you're assuming (and verify those assumptions)
- State what you're unsure about and need to investigate
- State what you tried that didn't work (failures are valuable data)

**Example of Good Communication**:
```
I verified the BookGen build script exists at .bookgen/build.sh.
I tested it locally and it successfully generated 41 HTML pages.
I'm now updating the workflow file to use this build script.
I'm unsure if the deploy-pages action supports PR previews automatically - 
I'll check the action documentation.
```

**Example of Bad Communication** (DON'T DO THIS):
```
The workflow is now configured and should work perfectly.
All tests pass.
The PR preview feature is enabled.
```

### 4. **Incremental Progress** üìä

- Make small, verifiable changes
- Test after each change
- Report progress frequently with concrete evidence
- Use checklists to track what's done vs. what's pending
- Commit working states, not untested changes

### 5. **Error Honesty** üîç

When you encounter errors:
- **ALWAYS** include the actual error message
- **ALWAYS** show what you tried to fix it
- **ALWAYS** explain why the fix should work (with references if needed)
- If a fix doesn't work, say so and try a different approach

**Don't hide failures or pretend everything is fine when it's not.**

---

## Repository-Specific Guidelines

### This Repository's Tech Stack

- **Documentation Generator**: BookGen (Python-based, custom GitBook alternative)
- **Build Script**: `.bookgen/build.sh`
- **Required Files**: `book.json`, `SUMMARY.md`, `readme.md`
- **Output Directory**: `_book/` (excluded from git)
- **CI/CD**: GitHub Actions with GitHub Pages deployment
- **Python Version**: 3.11
- **Required Python Package**: `markdown`

### Common Tasks

#### 1. Testing the Build Locally

```bash
cd /home/runner/work/ai-learning/ai-learning
chmod +x ./.bookgen/build.sh
./.bookgen/build.sh
# Verify output: ls -la _book/
```

#### 2. Validating Required Files

```bash
# These files MUST exist for BookGen to work
test -f book.json && echo "‚úÖ book.json exists"
test -f SUMMARY.md && echo "‚úÖ SUMMARY.md exists"
test -f readme.md && echo "‚úÖ readme.md exists"
```

#### 3. Checking Workflow Syntax

```bash
# GitHub doesn't provide a local validator, but you can:
# - Review the YAML syntax carefully
# - Check for proper indentation
# - Verify action versions are valid
```

#### 4. Understanding the Deployment Flow

1. **Push to main** ‚Üí Build ‚Üí Deploy to production GitHub Pages
2. **Pull request** ‚Üí Build ‚Üí GitHub creates preview deployment automatically
3. **Workflow dispatch** ‚Üí Build ‚Üí Deploy to production GitHub Pages

**Important**: The `deploy` job only runs on push/workflow_dispatch. PR previews are handled automatically by GitHub when a Pages artifact is uploaded.

---

## Anti-Hallucination Checklist

Before claiming any work is complete, verify:

- [ ] **Did I actually run the code?** (not just read it)
- [ ] **Did I check the output?** (not just assume it worked)
- [ ] **Did I read the actual files?** (not guess at their content)
- [ ] **Did I test the changes?** (not just "it should work")
- [ ] **Did I verify dependencies exist?** (not assume they're installed)
- [ ] **Did I check error logs if something failed?** (not skip over them)
- [ ] **Am I reporting what actually happened?** (not what I hoped would happen)

---

## Progress Tracking

All work on this repository should be tracked using:

1. **Progress Log**: `docs/ops/PROGRESS.md` - What you're doing, why, and results
2. **Decision Log**: `docs/ops/DECISIONS.md` - Major decisions with rationale
3. **PR Template**: `.github/pull_request_template.md` - Structured PR descriptions

These files enforce:
- Clear documentation of assumptions
- Explicit citation of sources
- Risk identification
- Next steps planning

---

## Red Flags (Things That Should Make You Stop and Verify)

üö© **"It should work"** ‚Üí Did you test it?  
üö© **"All tests pass"** ‚Üí Did you actually run the tests?  
üö© **"The workflow will now..."** ‚Üí Did you verify this or are you guessing?  
üö© **"This file contains..."** ‚Üí Did you read the file or assume its content?  
üö© **"The error is caused by..."** ‚Üí Did you see the actual error message?  

---

## Model-Specific Notes (Claude 3.5 Sonnet via AWS Bedrock)

**Strengths**:
- Strong code analysis and generation
- Excellent at structured documentation
- Good at following explicit instructions

**Watch Out For**:
- Tendency to be overly confident in untested code
- May assume features exist without verification
- Can skip error checking if not explicitly prompted

**Best Practices**:
- Always use the test/verify cycle explicitly
- Break complex tasks into verifiable steps
- Ask for confirmation when uncertain

---

## When Things Go Wrong

### A. Build Failures

1. Read the full error output (don't skim)
2. Check if required files are missing
3. Verify Python and dependencies are installed
4. Test the build script directly before blaming the workflow

### B. Deployment Failures

1. Check GitHub Pages is enabled (Settings ‚Üí Pages ‚Üí Source: GitHub Actions)
2. Verify workflow permissions are correct
3. Check if the artifact was uploaded successfully
4. Review deploy job logs for specific errors

### C. PR Preview Not Working

1. Verify the build job completed successfully
2. Check that Pages source is set to "GitHub Actions"
3. Confirm the artifact was uploaded
4. Note: PR previews are automatic, the deploy job intentionally doesn't run for PRs

---

## Success Criteria

You've done a good job when:

‚úÖ Every claim you made is backed by actual evidence  
‚úÖ You tested changes before reporting them as complete  
‚úÖ You documented what you tried, including failures  
‚úÖ You asked questions when you were uncertain  
‚úÖ You provided concrete next steps based on actual results  
‚úÖ Someone else could reproduce your work from your documentation  

---

## Summary: The Golden Rule

**"Say what you know. Show your work. Test everything."**

When in doubt, verify. When you can't verify, say so. Never pretend to know something you don't. This is how we build reliable systems and maintain trust.

---

_This document should be updated as we learn more about what works and what doesn't. If you discover new pitfalls or best practices, add them here._
